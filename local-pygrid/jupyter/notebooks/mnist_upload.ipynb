{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificien Sample Model Upload\n",
    "Here, we demonstrate how to create a machine learning model and upload it so that it may be trained on client devices using federated learning.\n",
    "We create a simple linear regression model below, defined in PyTorch syntax, to predict a single variable 'Y' using another variable 'X'. We then upload the model to our 'PyGrid' node. Models sent to this PyGrid node will be downloaded by client devices (iPhones, Androids, etc.) and trained on local data. Each time a device or set of devices trains your model, the model stored on the PyGrid node will be updated, to reflect the newly improved model.\n",
    "\n",
    "As soon as you upload the below tutorial model, you'll find it on artificien.com on your 'models' page. There, you'll be able to check the model progress and download the newly trained model once training is complete.\n",
    "\n",
    "**PLEASE READ**: \n",
    "- Because this is a tutorial and this model is not built to make predictions on real data, models uploaded via this tutorial will not actually be sent to client devices.\n",
    "\n",
    "- You cannot save changes made to this tutorial - this file is shared by all Artificien users and cannot be altered. To create your own notebooks (which can be edited and saved), create a new notebook in your root ('/') directory, or make a copy of this notebook and place it in your root directory.\n",
    "\n",
    "- To build models for deployment to actual devices running Artificien partner apps, ensure that your model can train on and make predictions using the provided [sample dataset](../sample_data) corresponding to the type of data you'd like to build on top of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syftfunctions as sf\n",
    "import torch as th\n",
    "from torch import nn\n",
    "import os\n",
    "\n",
    "import syft as sy\n",
    "from syft.federated.fl_client import FLClient\n",
    "from syft.federated.fl_job import FLJob\n",
    "from syft.grid.clients.model_centric_fl_client import ModelCentricFLClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Model\n",
    "Here, we define our model using standard pytorch model definition. This example is just a simple 3 variable linear classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 392)\n",
    "        self.fc2 = nn.Linear(392, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Enter Password\n",
    "Enter your artificien password bellow so artificien can validate your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = \"artificien1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check available datasets\n",
    "Check the datasets that you've purchased access to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': ['dataSetFive', 'FOUR', 'localHostTestSet']}\n"
     ]
    }
   ],
   "source": [
    "sf.get_my_purchased_datasets(password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this tutorial, we've selected dataSetFive for you and named your model perceptron. You can change these things when building your own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"client-model\"\n",
    "dataset = \"dataSetFive\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a Training Plan\n",
    "First, we must choose some dummy X and Y representative of our input and output parameters respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = th.randn(3, 28 * 28)\n",
    "y = nn.functional.one_hot(th.tensor([1, 2, 3]), 10)\n",
    "lr = 0.01\n",
    "batch_size = 3\n",
    "model_params, training_plan = sf.def_training_plan(model, X, y, {\"loss\": sf.softmax_cross_entropy_with_logits})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining an Averaging Plan\n",
    "Next we define our averaging plan - the way our model averages the results from multiple edge devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_plan = sf.def_avg_plan(model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send Model\n",
    "Next, we sent the model to artificien's infrastructure to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['test_f1', 'test_f2']; labels = ['test_l1', 'test_l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host response: {'type': 'model-centric/host-training', 'data': {'status': 'success'}}\n"
     ]
    }
   ],
   "source": [
    "sf.send_model(name=name, dataset_id=dataset, version=\"1.0\", batch_size=32, learning_rate=0.2, max_updates=10,\n",
    "              model_params=model_params, training_plan=training_plan, avg_plan=avg_plan, \n",
    "              features=features, labels=labels, password=password)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
